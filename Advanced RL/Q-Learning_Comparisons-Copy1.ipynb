{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31afbd0b-485d-4c1d-b22f-f6277c77f504",
   "metadata": {},
   "source": [
    "Note: for Jarvis Labs need to install the following packages:\n",
    "* pygame - `pip install -U pygame --user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91601b-3313-431d-b53e-e25d70b1b555",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Reinforcment Learning for Snake Game\n",
    "\n",
    "We want to train an agent to play Snake. The Snake starts as 3 squares long and has to move around a constrained space and eat rats. One rat appears randomly at a time. If the snake crashes into its own body or the walls, it dies. If it eats a rat, it scores a point and grows one square longer. \n",
    "\n",
    "We aim to train our agent to score highly in the game.\n",
    "\n",
    "We used several different approaches. Firstly, the way that the snake perceives it's environment might make a difference.\n",
    "\n",
    "The `get_observation` method of Agent class gives a ndarray (converted to tensor) representing the snakes perceived environment. We designed three versions. All are flat arrays with values of 0 or 1 representing False and True. All have 4 entries which represent whether the rat is ahead, behind, left or right of the snake (relative to the direction the snake is facing).\n",
    "* Simple. ndarry of shape (11,). 3 values representing if there is a fatal collision directly infront-of, left or right of the snakes head. 4 values to represent if the snake is facing up, down, left or right. 4 values representing relative position of rat.\n",
    "* Surroundings. ndarray of shape (29,). 25 values representing the squares in the 5x5 area around the snakes head: relative to the direction the snake is facing. Values are 1 if square is occupied by the snake's body or a wall, 0 otherwise. 4 values representing relative position of the rat.\n",
    "* Relative_Snake. ndarray of shape (12,). The first four values indicate whether any portion of the snake's body is ahead, behind, left of right from where the snake is facing. The hope is that it learns to steer away from it's own body to avoid collisions. The next four values represent an immediate collision ahead, behind, left or right of the snake. The last four values represent the relative position of the rat.\n",
    "\n",
    "In addition to this we have several approaches to learning the optimum policy:\n",
    "* Deep Q-Learning\n",
    "* Double Deep Q-Learning\n",
    "* Dueling Networks.\n",
    "\n",
    "Finally, with no real adjustment to the code, our representation of the environment is conjucive to curriculum learning: we can train the agent on smaller (easier) environments and then test it - even on zero shot basis - against the full size environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c430badc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.8.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM default\n"
     ]
    }
   ],
   "source": [
    "from Game import SnakeGameAI\n",
    "from helper import training_loop, plot, ax_plot\n",
    "from collections import namedtuple\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f2d995-aca5-4dc8-8ec8-71b984d54162",
   "metadata": {},
   "source": [
    "Set some global variables we will use for most games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5109cac-efa6-45f2-8472-2416d56a00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "UI = False\n",
    "TRAINING_EPISODES = 1500\n",
    "EVALUATION_EPISODES = 30\n",
    "DQN_Style = {'DQN': {'double_dqn': False, 'dueling_dqn': False},\n",
    "             'Double_DQN': {'double_dqn': True, 'dueling_dqn': False},\n",
    "             'Dueling_DQN': {'double_dqn': False, 'dueling_dqn': True},\n",
    "             'Double_Dueling_DQN': {'double_dqn': True, 'dueling_dqn': True}}\n",
    "Output = namedtuple('Output', ['agent', 'scores', 'mean_scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23397247-d748-4c67-bb8b-2476705222e9",
   "metadata": {},
   "source": [
    "Charts below just help us calibrate epsilon greedy parameters. We have hardcoded the epsilon floor of 0.05. Starting epsilon and epsilon decay for epsilon > or < 0.5 can be set. Epsilon is updated after each episode. We choose epsilon to decay from a high number to a low number over the course of training. The 200 and 250 episode cases are for curriculum learning, where the model has already been trained a bit, so epsilon starts lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9015dc7c-954f-4853-bb1c-30cb6a1a49c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def epsilon_decay(steps, e, e_decay, min_e=0.05):\n",
    "    a = np.ones(steps) * e_decay[0]\n",
    "    b = np.ones(steps) * e_decay[1]\n",
    "    aa = np.cumproduct(a) * e\n",
    "    bb = np.cumproduct(b) * e\n",
    "    thresh_idx = np.argmax(aa < 0.5)\n",
    "    eps = np.where(aa > 0.5, aa,\n",
    "                   aa[thresh_idx] / bb[thresh_idx] * bb)\n",
    "    eps = np.where(eps > min_e, eps, min_e)\n",
    "    return eps\n",
    "\n",
    "fig, axs = plt.subplots(1,4,sharey=True, figsize=(10,2))\n",
    "\n",
    "eps_list = []\n",
    "eps_list.append(epsilon_decay(150, 0.9, [0.99, 0.98]))\n",
    "eps_list.append(epsilon_decay(200, 0.8, [0.993, 0.987]))\n",
    "eps_list.append(epsilon_decay(250, 0.7, [0.994, 0.992]))\n",
    "eps_list.append(epsilon_decay(1500, 0.9, [0.999, 0.998]))\n",
    "steps_list = [150, 200, 250, 1500]\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.plot(eps_list[i])\n",
    "    ax.set_title(\"{} episodes\\nmin e = {:.2f}\"\n",
    "                 .format(steps_list[i], eps_list[i][-1]))\n",
    "                 \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3ff92-72b9-44e4-938f-a9725aa1f01f",
   "metadata": {},
   "source": [
    "## Different approaches to observed environment\n",
    "\n",
    "With the basic DQN approach, we can see which representation of the environment looks most promising. We will train the snake for 1000 episodes for each representation and then evaluate over 20 episodes using the optimum learned policy. \n",
    "\n",
    "We will use this representation of the environment for comparison of different learning algorithms.\n",
    "\n",
    "### 1. get_observation_simple\n",
    "\n",
    "First train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706a2973-ed87-4068-b148-97be89c18e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '_simple.pth'\n",
    "SAVE_NAME = '_simple_best.pth'\n",
    "GET_OBS='simple'\n",
    "simple_output_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a589984-9a23-4974-88bb-84cf00530102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##################--] 89.7%\n",
      "Double_Dueling_DQN_simple; episode: 1345\n"
     ]
    }
   ],
   "source": [
    "for key, val in DQN_Style.items():\n",
    "    game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                    'window_title': \"{} - {}\".format(key, GET_OBS)}\n",
    "\n",
    "    agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                               model_name=key + MODEL_NAME,\n",
    "                                               load_model=False,\n",
    "                                               save_name=key + SAVE_NAME,\n",
    "                                               episode_save = 350,\n",
    "                                               get_observation=GET_OBS,\n",
    "                                               greedy=True,\n",
    "                                               **val, # dict for kwargs\n",
    "                                               num_episodes=TRAINING_EPISODES,\n",
    "                                               plot_update_at_end=True\n",
    "                                              )\n",
    "    agent.save_model(key + MODEL_NAME)\n",
    "    simple_output_dict[key] = Output(agent, scores, mean_scores)\n",
    "\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a1567-f883-46f7-9cb3-a73525e246ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. get_observation_surroundings\n",
    "\n",
    "First train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8394de-fadb-4d6a-8986-abdc08888aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '_surroundings.pth'\n",
    "SAVE_NAME = '_surroundings_best.pth'\n",
    "GET_OBS='surroundings'\n",
    "surroundings_output_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabe39b-d65f-49d7-a4b1-7ce86f0dc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in DQN_Style.items():\n",
    "    game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                    'window_title': \"{} - {}\".format(key, GET_OBS)}\n",
    "\n",
    "    agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                               model_name=key + MODEL_NAME,\n",
    "                                               load_model=False,\n",
    "                                               save_name=key + SAVE_NAME,\n",
    "                                               episode_save = 350,\n",
    "                                               get_observation=GET_OBS,\n",
    "                                               greedy=True,\n",
    "                                               **val, # dict for kwargs\n",
    "                                               num_episodes=TRAINING_EPISODES,\n",
    "                                               plot_update_at_end=True\n",
    "                                              )\n",
    "    agent.save_model(key + MODEL_NAME)\n",
    "    surroundings_output_dict[key] = Output(agent, scores, mean_scores)\n",
    "\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a717592c-556f-44dc-995d-f6db5216902d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. get_observation_relative_snake\n",
    "\n",
    "First train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62310e6-082d-4685-86b7-2678c4d122ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '_relative.pth'\n",
    "SAVE_NAME = '_relative_best.pth'\n",
    "GET_OBS='relative_snake'\n",
    "relative_output_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536c693-e7c3-4ac0-b714-9192a4b3ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in DQN_Style.items():\n",
    "    game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                    'window_title': \"{} - {}\".format(key, GET_OBS)}\n",
    "\n",
    "    agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                               model_name=key + MODEL_NAME,\n",
    "                                               load_model=False,\n",
    "                                               save_name=key + SAVE_NAME,\n",
    "                                               episode_save = 350,\n",
    "                                               get_observation=GET_OBS,\n",
    "                                               greedy=True,\n",
    "                                               **val, # dict for kwargs\n",
    "                                               num_episodes=TRAINING_EPISODES,\n",
    "                                               plot_update_at_end=True\n",
    "                                              )\n",
    "    agent.save_model(key + MODEL_NAME)\n",
    "    relative_output_dict[key] = Output(agent, scores, mean_scores)\n",
    "\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999307e1-165d-4434-8964-83749060474b",
   "metadata": {},
   "source": [
    "### Display results of training\n",
    "\n",
    "Score of individual episodes in blue, moving average in green, average for episodes plays so far in orange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc84a3-a6c1-4138-95ca-95de390b156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, sharex=True, sharey=True, figsize=(12,8))\n",
    "outputs = {'simple': simple_output_dict,\n",
    "          'surroundings': surroundings_output_dict,\n",
    "          'relative_snake': relative_output_dict}\n",
    "\n",
    "output_list = []\n",
    "for out_key, out_val in outputs.items():\n",
    "    for key, val in out_val.items():\n",
    "        output_list.append(['observations: {}\\nRL algorithm: {}'.format(out_key, key),\n",
    "                            val.scores, val.mean_scores, val.agent.epsilon])\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax_plot(ax, output_list[i][1], output_list[i][2], title=output_list[i][0])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589f08b-6e05-4752-8204-5dcba477b324",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation of algorithm performance\n",
    "\n",
    "We run 20 episodes of each algorithm and observation combination, with each making the optimal policy choice (no randomness).\n",
    "\n",
    "We se same random seed for each game so that evaluations are comparible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7c933-3711-4313-bfa0-2ff21f837812",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "for out_key in ['simple', 'surroundings', 'relative']:\n",
    "    for key, val in DQN_Style.items():\n",
    "        game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                       'window_title': \"{} - {}\".format(key, out_key)\n",
    "                      }\n",
    "        agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                                   model_name='{}_{}.pth'.format(key, out_key),\n",
    "                                                   load_model=True,\n",
    "                                                   get_observation=out_key,\n",
    "                                                   greedy=False,\n",
    "                                                   **val, # dict for kwargs\n",
    "                                                   num_episodes=EVALUATION_EPISODES,\n",
    "                                                   plot_update_at_end=True,\n",
    "                                                   random_seed=1\n",
    "                                                  )\n",
    "        eval_dict[\"{} - {}\".format(key, out_key)] = Output(agent, scores, mean_scores)\n",
    "        \n",
    "display.clear_output(wait=True)\n",
    "        \n",
    "fig, axs = plt.subplots(3, 4, sharex=True, sharey=True, figsize=(12,8))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    scores = list(eval_dict.values())[i].scores\n",
    "    mean_scores = list(eval_dict.values())[i].mean_scores\n",
    "    title = list(eval_dict.keys())[i]\n",
    "    \n",
    "    ax_plot(ax, scores, mean_scores, window=None, title=title)\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e5f6a-fdfe-42be-87ee-a7fcf2a31075",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Curriculum Learning\n",
    "\n",
    "### First stage\n",
    "\n",
    "First we train the agent on a really small grid - equivalent to 6 x 6 blocks.\n",
    "\n",
    "The intuition is that the snake will spend more time learning to avoid walls, and also be more likley to randomly eat a rat and discover that it's worth finding the rat when the grid is smaller.\n",
    "\n",
    "### Second stage\n",
    "\n",
    "Now we train the agent on a slightly larger grid: 10 x 10 blocks.\n",
    "\n",
    "The grid is large enough the the snake's observation field (5 x 5 blocks surrounding snakes head) is always missing quite a bit of information about the full environment. The snake should train to factor in the relative lack of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b780ba-bb05-46e1-a7c0-66fdd2b73d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "UI = False\n",
    "TRAINING_EPISODES = 150\n",
    "EVAL_EPISODES = 30\n",
    "GET_OBS = 'surroundings'\n",
    "DOUBLE_DQN = False\n",
    "DUELING_DQN = True\n",
    "MODEL_NAME = 'small_grid.pth'\n",
    "EPS_KW = {'epsilon': 0.9, 'epsilon_decay':[0.99, 0.98]}\n",
    "curriculum_output = {}\n",
    "\n",
    "game_kwargs = {'width': 120, 'height': 120, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=MODEL_NAME,\n",
    "                                           load_model=False,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=True,\n",
    "                                           epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=TRAINING_EPISODES,\n",
    "                                           plot_update_at_end=True\n",
    "                                          )\n",
    "agent.save_model(MODEL_NAME)\n",
    "curriculum_output[MODEL_NAME.split(',')[0]] = Output(agent, scores, mean_scores)\n",
    "\n",
    "################\n",
    "# SECOND STAGE:\n",
    "################\n",
    "\n",
    "\n",
    "TRAINING_EPISODES = 200\n",
    "LOAD_NAME = 'small_grid.pth'\n",
    "SAVE_NAME = 'medium_grid.pth'\n",
    "EPS_KW = {'epsilon': 0.9, 'epsilon_decay':[0.992, 0.985]}\n",
    "\n",
    "game_kwargs = {'width': 200, 'height': 200, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=LOAD_NAME,\n",
    "                                           load_model=True,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=True,\n",
    "                                           epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=TRAINING_EPISODES,\n",
    "                                           plot_update_at_end=True\n",
    "                                          )\n",
    "agent.save_model(SAVE_NAME)\n",
    "curriculum_output[SAVE_NAME.split(',')[0]] = Output(agent, scores, mean_scores)\n",
    "\n",
    "display.clear_output()\n",
    "\n",
    "keys = list(curriculum_output.keys())\n",
    "titles = ['small grid training', 'medium grid training']\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(8, 3))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax_plot(ax, curriculum_output[keys[i]].scores,\n",
    "            curriculum_output[keys[i]].mean_scores,\n",
    "            title=titles[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b36b50-c523-42e6-a09e-d53a5da45fd4",
   "metadata": {},
   "source": [
    "### Zero shot\n",
    "\n",
    "Evaluate the model trained so far on the full-sized grid. How does it compete with the other agents that have trained for 1500 episodes on the full-sized grid?\n",
    "\n",
    "It does! The agent outperforms all previous agents despite having only trained for 300 episodes on very simple problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bfa56-2ce0-4169-b27c-9f718e71450f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using new obserations\n",
    "LOAD_NAME = 'medium_grid.pth'\n",
    "# SAVE_NAME = 'medium_grid.pth'\n",
    "# EPS_KW = {'epsilon': 0.9, 'epsilon_decay':[0.992, 0.985]}\n",
    "\n",
    "game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=LOAD_NAME,\n",
    "                                           load_model=True,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=False,\n",
    "                                           # epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=EVAL_EPISODES,\n",
    "                                           plot_update_at_end=True,\n",
    "                                           random_seed=1\n",
    "                                          )\n",
    "\n",
    "zero_shot_output = Output(agent, scores, mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2954d-15d3-4cd6-b4e0-8446d4ef5a23",
   "metadata": {},
   "source": [
    "### Third round: train on full-sized grid, epsilon starts at 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1eb8b-8b99-4d28-8fd9-a674a8aa0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EPISODES = 250\n",
    "LOAD_NAME = 'medium_grid.pth'\n",
    "SAVE_NAME = 'full_gridv2.pth'\n",
    "EPS_KW = {'epsilon': 0.7, 'epsilon_decay':[0.994, 0.992]}\n",
    "\n",
    "game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=LOAD_NAME,\n",
    "                                           load_model=True,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=True,\n",
    "                                           epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=TRAINING_EPISODES,\n",
    "                                           plot_update_at_end=True\n",
    "                                          )\n",
    "agent.save_model(SAVE_NAME)\n",
    "curriculum_output[SAVE_NAME.split(',')[0]] = Output(agent, scores, mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06571c78-0f03-4990-8778-8d49386f7958",
   "metadata": {},
   "source": [
    "### Evaluate: full-sized grid, third round, epsilon = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e41ee-c4df-455b-8eef-6da1049e3d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using new obserations\n",
    "LOAD_NAME = 'full_gridv2.pth'\n",
    "# SAVE_NAME = 'medium_grid.pth'\n",
    "# EPS_KW = {'epsilon': 0.9, 'epsilon_decay':[0.992, 0.985]}\n",
    "\n",
    "game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=LOAD_NAME,\n",
    "                                           load_model=True,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=False,\n",
    "                                           # epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=EVAL_EPISODES,\n",
    "                                           plot_update_at_end=True,\n",
    "                                           random_seed=1\n",
    "                                          )\n",
    "\n",
    "eval_output = Output(agent, scores, mean_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e95556-260b-4e79-b4ba-dbb6b42406b2",
   "metadata": {},
   "source": [
    "### Try third round on \"medium-plus\" grid\n",
    "\n",
    "The jump from a 10x10 to a 32x24 grid is quite big. What happens if we train on a 20x16 grid as a third round and then evaluate on zero shot or fourth round of training on full-sized grid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba47988-66f5-4e9f-9a02-d76d3a60a21e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_EPISODES = 250\n",
    "LOAD_NAME = 'medium_grid.pth'\n",
    "SAVE_NAME = 'medium_plus_grid.pth'\n",
    "EPS_KW = {'epsilon': 0.7, 'epsilon_decay':[0.994, 0.992]}\n",
    "\n",
    "game_kwargs = {'width': 400, 'height': 320, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=LOAD_NAME,\n",
    "                                           load_model=True,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=True,\n",
    "                                           epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=TRAINING_EPISODES,\n",
    "                                           plot_update_at_end=True\n",
    "                                          )\n",
    "agent.save_model(SAVE_NAME)\n",
    "curriculum_output[SAVE_NAME.split(',')[0]] = Output(agent, scores, mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7ae03-354c-48f1-a473-d49e311625e9",
   "metadata": {},
   "source": [
    "### Zero shot evaluation after 3 rounds of curriculum training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b3602-b563-4000-b7c2-d86a0357d480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using new obserations\n",
    "LOAD_NAME = 'medium_plus_grid.pth'\n",
    "# SAVE_NAME = 'medium_grid.pth'\n",
    "# EPS_KW = {'epsilon': 0.9, 'epsilon_decay':[0.992, 0.985]}\n",
    "\n",
    "game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=LOAD_NAME,\n",
    "                                           load_model=True,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=False,\n",
    "                                           # epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=EVAL_EPISODES,\n",
    "                                           plot_update_at_end=True,\n",
    "                                           random_seed=1\n",
    "                                          )\n",
    "\n",
    "eval_output = Output(agent, scores, mean_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90a33d-ca09-4c5a-af6e-75c39fa7f523",
   "metadata": {},
   "source": [
    "### 4th round of training - full-sized grid, epsilon = 0.7\n",
    "\n",
    "This agent has trainded on 6x6, 10x10, 10x16 and finall on 32x24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bce661-8ca7-495d-90b3-8eedf94acf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_EPISODES = 250\n",
    "LOAD_NAME = 'medium_plus_grid.pth'\n",
    "SAVE_NAME = 'full_gridv3.pth'\n",
    "EPS_KW = {'epsilon': 0.7, 'epsilon_decay':[0.994, 0.992]}\n",
    "\n",
    "game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=LOAD_NAME,\n",
    "                                           load_model=True,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=True,\n",
    "                                           epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=TRAINING_EPISODES,\n",
    "                                           plot_update_at_end=True\n",
    "                                          )\n",
    "agent.save_model(SAVE_NAME)\n",
    "curriculum_output[SAVE_NAME.split(',')[0]] = Output(agent, scores, mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb63bdd-d306-4e10-b27e-40b7f1999961",
   "metadata": {},
   "source": [
    "### Evaluate after 4 training rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70d31a-ba48-4b1c-815a-8b95861c1604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using new obserations\n",
    "LOAD_NAME = 'full_gridv3.pth'\n",
    "# SAVE_NAME = 'medium_grid.pth'\n",
    "# EPS_KW = {'epsilon': 0.9, 'epsilon_decay':[0.992, 0.985]}\n",
    "\n",
    "game_kwargs = {'width': 640, 'height': 480, 'UI': UI,\n",
    "                'window_title': \"{}\".format(GET_OBS)}\n",
    "\n",
    "agent, scores, mean_scores = training_loop(game_kwargs=game_kwargs,\n",
    "                                           model_name=LOAD_NAME,\n",
    "                                           load_model=True,\n",
    "                                           get_observation=GET_OBS,\n",
    "                                           greedy=False,\n",
    "                                           # epsilon_kwargs=EPS_KW,\n",
    "                                           double_dqn=DOUBLE_DQN,\n",
    "                                           dueling_dqn=DUELING_DQN,\n",
    "                                           num_episodes=EVAL_EPISODES,\n",
    "                                           plot_update_at_end=True,\n",
    "                                           random_seed=1\n",
    "                                          )\n",
    "\n",
    "eval_output = Output(agent, scores, mean_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f732c-186d-44df-a414-e28d4ff444c4",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
